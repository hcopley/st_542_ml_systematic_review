{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hcopley/st_542_ml_systematic_review/blob/main/data_explo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initial Data Exploration\n",
        "Programmed by: Andras Paul\n",
        "\n",
        "Programmed on: 2/5/26\n",
        "\n",
        "Programmed to: Read articles data in and perform data exploration"
      ],
      "metadata": {
        "id": "SkaZZEt_0yG3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Important packages\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "l1MlDrTEJ1m-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eDe0uKMdzfew"
      },
      "outputs": [],
      "source": [
        "# Import and download more resources\n",
        "!pip -q install gdown\n",
        "import gdown, os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read large text file from google drive\n",
        "file_id = '1IHspcqlg_Tz44-vmL-PNQOqUkSY_zOgd'\n",
        "url = f'https://drive.google.com/uc?id={file_id}'\n",
        "out = 'large_file.txt'\n",
        "gdown.download(url, out, quiet=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "48dymwUT9-Ko",
        "outputId": "7c0c4c2a-eb57-4c0b-b06e-fac9778a7825"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1IHspcqlg_Tz44-vmL-PNQOqUkSY_zOgd\n",
            "From (redirected): https://drive.google.com/uc?id=1IHspcqlg_Tz44-vmL-PNQOqUkSY_zOgd&confirm=t&uuid=03490e2c-01b7-46de-a80d-c046f36a270b\n",
            "To: /content/large_file.txt\n",
            "100%|██████████| 107M/107M [00:00<00:00, 215MB/s] \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'large_file.txt'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read\n",
        "with open(out, 'r', encoding='utf-8', errors='replace') as f:\n",
        "    for i, line in enumerate(f):\n",
        "        if i < 5:\n",
        "            print(line.rstrip())\n",
        "        else:\n",
        "            pass"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1L9hf9Mh-Ag-",
        "outputId": "d56fd1e0-d5ad-4108-8160-6d7842b0c685"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"index\",\"dupflag\",\"src\",\"recnum\",\"pubtype\",\"authors\",\"editor\",\"year\",\"y1\",\"y2\",\"date\",\"title\",\"title2\",\"series\",\"journal\",\"jabbr\",\"volume\",\"number\",\"startpage\",\"endpage\",\"place\",\"publisher\",\"url\",\"doi\",\"language\",\"abstract\",\"keywords\",\"address\",\"notes\",\"dbprovider\",\"database\",\"accession\",\"id\",\"issn_isbn\",\"custom1\",\"custom2\",\"custom3\",\"custom4\",\"code\"\n",
            "\"1\",\"0\",\"02\",\"53\",\"ELEC\",\"Tufanaru, Catalin [MD, MPH, MClinSci]\",\"\",\"2015//\",\"\",\"\",\"\",\"Acute Mental Health Care: Physical Restraint (Effectiveness and Use)\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"http://ovidsp.ovid.com/ovidweb.cgi?T=JS&PAGE=reference&D=jbi&NEWS=N&AN=JBI13242\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"JBI13242\",\"\",\"\",\"\",\"\",\"\",\"\"\n",
            "\"2\",\"0\",\"02\",\"29\",\"ELEC\",\"Slade, Susan [BScApp (Physio), Grad Dip Manip Ther, M Musc Ther, PhD]\",\"\",\"2015//\",\"\",\"\",\"\",\"Administration of PRN Analgesia\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"http://ovidsp.ovid.com/ovidweb.cgi?T=JS&PAGE=reference&D=jbi&NEWS=N&AN=JBI5270\",\"\",\"\",\"\",\"Analgesia\",\"\",\"\",\"\",\"\",\"\",\"JBI5270\",\"\",\"\",\"\",\"\",\"\",\"\"\n",
            "\"3\",\"0\",\"02\",\"16\",\"ELEC\",\"Dao Le, Long Khanh [B.Pharm, MPH, MHHSM]\",\"\",\"2015//\",\"\",\"\",\"\",\"Asylum Seekers/Refugees: Mental Health Implications\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"http://ovidsp.ovid.com/ovidweb.cgi?T=JS&PAGE=reference&D=jbi&NEWS=N&AN=JBI1748\",\"\",\"\",\"\",\"Refugees;Mental Health\",\"\",\"\",\"\",\"\",\"\",\"JBI1748\",\"\",\"\",\"\",\"\",\"\",\"\"\n",
            "\"4\",\"0\",\"02\",\"27\",\"ELEC\",\"Slade, Susan [BScApp (Physio), Grad Dip Manip Ther, M Musc Ther, PhD]\",\"\",\"2015//\",\"\",\"\",\"\",\"Attention Deficit Hyperactivity Disorder: Psychological Interventions\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"http://ovidsp.ovid.com/ovidweb.cgi?T=JS&PAGE=reference&D=jbi&NEWS=N&AN=JBI621\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"JBI621\",\"\",\"\",\"\",\"\",\"\",\"\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# read large_file.txt as a dataframe\n",
        "df0 = pd.read_csv('large_file.txt')"
      ],
      "metadata": {
        "id": "H1Knf9fGKt5w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check the dimension of the text file\n",
        "df0.shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qKkoGFx6NbFm",
        "outputId": "23094193-c0a9-46c0-e9cd-4329c70bd8a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(49104, 39)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check data readiness for BERT\n",
        "def check_bert_dataset(df, text_col=\"text\", label_col=None):\n",
        "  from transformers import BertTokenizer tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "  print(\"Checking text types...\")\n",
        "  print(df[text_col].apply(type).value_counts(), \"\\n\")\n",
        "  print(\"Missing values:\", df[text_col].isna().sum())\n",
        "  print(\"Empty strings:\", (df[text_col].str.strip() == \"\").sum(), \"\\n\")\n",
        "  print(\"Token length stats:\") token_lengths = df[text_col].apply(lambda x: len(tokenizer.encode(x, add_special_tokens=True)))\n",
        "  print(token_lengths.describe(), \"\\n\") if label_col:\n",
        "  print(\"Label distribution:\") print(df[label_col].value_counts())"
      ],
      "metadata": {
        "id": "-2jJmP2okvSf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check data readiness for Naïve Bayes (Multinomial)\n",
        "def check_nb_dataset(df, text_col=\"text\", label_col=\"label\"):\n",
        "  from sklearn.feature_extraction.text import CountVectorizer\n",
        "  from sklearn.preprocessing import LabelEncoder\n",
        "  import numpy as np print(\"Checking missing values...\")\n",
        "\n",
        "  print(df[[text_col, label_col]].isna().sum(), \"\\n\")\n",
        "  print(\"Checking empty text rows...\")\n",
        "\n",
        "  print((df[text_col].str.strip() == \"\").sum(), \"\\n\")\n",
        "  print(\"Checking label types...\") print(df[label_col].unique(), \"\\n\")\n",
        "\n",
        "  print(\"Vectorizing sample...\")\n",
        "  vectorizer = CountVectorizer()\n",
        "  X = vectorizer.fit_transform(df[text_col])\n",
        "\n",
        "  print(\"Vocabulary size:\", len(vectorizer.vocabulary_))\n",
        "  print(\"Any negative values in features:\", (X.data < 0).any())"
      ],
      "metadata": {
        "id": "jcRMZMzwoZvv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check data readiness for Logistic Regression with Stochastic Gradient Descent (SGD)\n",
        "def check_sgd_dataset(df, text_col=\"text\", label_col=\"label\"):\n",
        "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "    from sklearn.preprocessing import LabelEncoder\n",
        "    import numpy as np\n",
        "\n",
        "    print(\"Checking missing values...\")\n",
        "    print(df[[text_col, label_col]].isna().sum(), \"\\n\")\n",
        "\n",
        "    print(\"Checking empty text rows...\")\n",
        "    print((df[text_col].str.strip() == \"\").sum(), \"\\n\")\n",
        "\n",
        "    print(\"Checking label distribution...\")\n",
        "    print(df[label_col].value_counts(), \"\\n\")\n",
        "\n",
        "    print(\"Vectorizing sample...\")\n",
        "    vectorizer = TfidfVectorizer()\n",
        "    X = vectorizer.fit_transform(df[text_col])\n",
        "\n",
        "    print(\"Shape of feature matrix:\", X.shape)\n",
        "    print(\"Any negative values:\", (X.data < 0).any(), \"\\n\")\n",
        "\n",
        "    print(\"Checking feature scale (mean/std of TF-IDF values):\")\n",
        "    print(\"Mean:\", X.data.mean(), \"Std:\", X.data.std())\n"
      ],
      "metadata": {
        "id": "HdckgppipOHK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}